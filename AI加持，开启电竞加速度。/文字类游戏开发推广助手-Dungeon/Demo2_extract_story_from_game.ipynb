{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo2: extract story from game",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiiEZKY3J5CC"
      },
      "source": [
        "# Demo2: extract story from game log by using GPT-2 Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usnFZFmlKbAS"
      },
      "source": [
        "## Env setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnz5h26WGZtv"
      },
      "source": [
        "Install older TensorFlow version\n",
        "\n",
        "Source code relies on older TensorFlow version. Installing TF v1.15 seems to fix the issue of *ModuleNotFoundError when training the model*. (Workaround found here: https://colab.research.google.com/notebooks/tensorflow_version.ipynb#scrollTo=8UvRkm1JGUrk) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8f1U3QqOrUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82df24df-98c3-46a3-f058-64dde319152e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip -q install tensorflow==1.15 && pip -q install tensorflow-gpu==1.15\n",
        "!pip -q install 'tensorflow-estimator<1.15.0rc0,>=1.14.0rc0' --force-reinstall"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 44kB/s \n",
            "\u001b[K     |████████████████████████████████| 491kB 6.3MB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za4oaCp3Otzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c82ab10-6e73-4943-b1fa-bb34aa0a991c"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be3La1bOGLnr"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   # disable all debugging logs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brNPcGyQGP0L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a595d8d6-5a0c-4df1-8f66-473cc3266a3a"
      },
      "source": [
        "!git clone https://github.com/zhangabner/gpt-2/\n",
        "import os\n",
        "os.chdir('gpt-2')\n",
        "#Download model weights\n",
        "# !python download_model.py 117M\n",
        "# !python download_model.py 345M\n",
        "# !python download_model.py 774M\n",
        "!python download_model.py 117M # XL Model\n",
        "!pip3 -q install -r /content/gpt-2/reqs.txt\n",
        "#!pip3 -q install -r /content/gpt-2/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 336 (delta 4), reused 11 (delta 4), pack-reused 325\u001b[K\n",
            "Receiving objects: 100% (336/336), 4.68 MiB | 19.46 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Fetching checkpoint: 1.00kit [00:00, 974kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 3.57Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.04Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:02, 8.00Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 5.21Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 1.97Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.79Mit/s]                                                       \n",
            "\u001b[K     |████████████████████████████████| 92kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 614kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQpePV8wLL39",
        "outputId": "3a501a90-23e4-4af1-d7db-97d8932fda8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "5RXWyE3oLQiU",
        "outputId": "7e1015dd-91d9-4f29-9b1d-52c73cc63c73"
      },
      "source": [
        "gamename = \"o10r5q5game1.ulx\"\n",
        "file_read = '/content/drive/My Drive/'+gamename+'.play.txt'\n",
        "file_write = '/content/drive/My Drive/'+gamename+'.story.txt'\n",
        "fr = open(file_read,\"r+\") \n",
        "raw_text = fr.read() \n",
        "raw_text\n",
        "fw = open(file_write,\"w\") \n",
        "# fw.write(raw_text)\n",
        "raw_text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\'description\\': \\'-= Cubicle =-\\\\nWell, here we are in the cubicle. You try to gain information on your surroundings by using a technique you call \"looking.\"\\\\n\\\\nYou can see a desk. On the desk you see a folder.\\\\n\\\\nThere is a closed portal leading east. There is an exit to the west. Don\\\\\\'t worry, it is unblocked.\\\\n\\\\n\\\\n\\', \\'inventory\\': \\'You are carrying:\\\\n  a loaf of bread\\\\n\\\\n\\\\n\\', \\'admissible_commands\\': [\\'drop loaf of bread\\', \\'eat loaf of bread\\', \\'examine desk\\', \\'examine folder\\', \\'examine loaf of bread\\', \\'examine portal\\', \\'go west\\', \\'inventory\\', \\'look\\', \\'open portal\\', \\'put loaf of bread on desk\\', \\'take folder from desk\\'], \\'intermediate_reward\\': 1}1: go east -> reward=1, total_reward=1{\\'description\\': \\'-= Cubicle =-\\\\nWell, here we are in the cubicle. You try to gain information on your surroundings by using a technique you call \"looking.\"\\\\n\\\\nYou can see a desk. On the desk you see a folder.\\\\n\\\\nThere is an open portal leading east. There is an exit to the west. Don\\\\\\'t worry, it is unblocked.\\\\n\\\\n\\\\n\\', \\'inventory\\': \\'You are carrying:\\\\n  a loaf of bread\\\\n\\\\n\\\\n\\', \\'admissible_commands\\': [\\'close portal\\', \\'drop loaf of bread\\', \\'eat loaf of bread\\', \\'examine desk\\', \\'examine folder\\', \\'examine loaf of bread\\', \\'examine portal\\', \\'go east\\', \\'go west\\', \\'inventory\\', \\'look\\', \\'put loaf of bread on desk\\', \\'take folder from desk\\'], \\'intermediate_reward\\': 1}2: open portal -> reward=1, total_reward=2{\\'description\\': \"-= Recreation Zone =-\\\\nYou\\'ve fallen into an ordinary room. Your mind races to think of what kind of room would be ordinary. And then it hits you. Of course. You\\'re in the recreation zone.\\\\n\\\\nYou see a box. The box is empty, what a horrible day!\\\\n\\\\nThere is an open portal leading west. There is an open gate leading south.\\\\n\\\\nThere is a burger on the floor.\\\\n\\\\n\", \\'inventory\\': \\'You are carrying:\\\\n  a loaf of bread\\\\n\\\\n\\\\n\\', \\'admissible_commands\\': [\\'close box\\', \\'close gate\\', \\'close portal\\', \\'drop loaf of bread\\', \\'eat loaf of bread\\', \\'examine box\\', \\'examine burger\\', \\'examine gate\\', \\'examine loaf of bread\\', \\'examine portal\\', \\'go south\\', \\'go west\\', \\'insert loaf of bread into box\\', \\'inventory\\', \\'look\\', \\'take burger\\'], \\'intermediate_reward\\': 1}3: go east -> reward=1, total_reward=3{\\'description\\': \"-= Garage =-\\\\nYou arrive in a garage. A standard one.\\\\n\\\\nWere you looking for a shelf? Because look over there, it\\'s a shelf. You see a butterfly on the shelf.\\\\n\\\\nThere is an open gate leading north. You need an unblocked exit? You should try going west.\\\\n\\\\n\\\\n\", \\'inventory\\': \\'You are carrying:\\\\n  a loaf of bread\\\\n\\\\n\\\\n\\', \\'admissible_commands\\': [\\'close gate\\', \\'drop loaf of bread\\', \\'eat loaf of bread\\', \\'examine butterfly\\', \\'examine gate\\', \\'examine loaf of bread\\', \\'examine shelf\\', \\'go north\\', \\'go west\\', \\'inventory\\', \\'look\\', \\'put loaf of bread on shelf\\', \\'take butterfly from shelf\\'], \\'intermediate_reward\\': 1}4: go south -> reward=1, total_reward=4{\\'description\\': \"-= Garage =-\\\\nYou arrive in a garage. A standard one.\\\\n\\\\nWere you looking for a shelf? Because look over there, it\\'s a shelf. But the thing hasn\\'t got anything on it. Silly shelf, silly, empty, good for nothing shelf.\\\\n\\\\nThere is an open gate leading north. You need an unblocked exit? You should try going west.\\\\n\\\\n\\\\n\", \\'inventory\\': \\'You are carrying:\\\\n  a butterfly\\\\n  a loaf of bread\\\\n\\\\n\\\\n\\', \\'admissible_commands\\': [\\'close gate\\', \\'drop butterfly\\', \\'drop loaf of bread\\', \\'eat loaf of bread\\', \\'examine butterfly\\', \\'examine gate\\', \\'examine loaf of bread\\', \\'examine shelf\\', \\'go north\\', \\'go west\\', \\'inventory\\', \\'look\\', \\'put butterfly on shelf\\', \\'put loaf of bread on shelf\\'], \\'intermediate_reward\\': 1}5: take butterfly from shelf -> reward=2, total_reward=6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJmTER8RzRjS"
      },
      "source": [
        "# read from S3  and save in S3      ai play textgames save as log\n",
        "# read from S3  and save in S3      gpt2 read play log save as summary\n",
        "# in comprehend  read summary  save as topic modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6o4GFcrMKvw"
      },
      "source": [
        "os.chdir('src')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-AIEKzcbK6D",
        "outputId": "b882499d-1fd6-415d-a6b8-a4bd2445b1c5"
      },
      "source": [
        "import fire\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import model, sample, encoder\n",
        "model_name='117M'\n",
        "seed=None\n",
        "nsamples=3\n",
        "batch_size=1\n",
        "length=100\n",
        "temperature=1\n",
        "top_k=0\n",
        "top_p=1\n",
        "models_dir='/content/gpt-2/models'\n",
        "\n",
        "models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "if batch_size is None:\n",
        "    batch_size = 1\n",
        "assert nsamples % batch_size == 0\n",
        "\n",
        "enc = encoder.get_encoder(model_name, models_dir)\n",
        "hparams = model.default_hparams()\n",
        "with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "    hparams.override_from_dict(json.load(f))\n",
        "\n",
        "if length is None:\n",
        "    length = hparams.n_ctx // 2\n",
        "elif length > hparams.n_ctx:\n",
        "    raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "with tf.Session(graph=tf.Graph()) as sess:\n",
        "    context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "    np.random.seed(seed)\n",
        "    tf.set_random_seed(seed)\n",
        "    output = sample.sample_sequence(\n",
        "        hparams=hparams, length=length,\n",
        "        context=context,\n",
        "        batch_size=batch_size,\n",
        "        temperature=temperature, top_k=top_k, top_p=top_p\n",
        "    )\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "    saver.restore(sess, ckpt)\n",
        "\n",
        "    context_tokens = enc.encode(raw_text)\n",
        "    generated = 0\n",
        "    for _ in range(nsamples // batch_size):\n",
        "        out = sess.run(output, feed_dict={\n",
        "            context: [context_tokens for _ in range(batch_size)]\n",
        "        })[:, len(context_tokens):]\n",
        "        for i in range(batch_size):\n",
        "            generated += 1\n",
        "            text = enc.decode(out[i])\n",
        "            print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "            print(text)\n",
        "            fw.write(text)\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gpt-2/models/117M/model.ckpt\n",
            "======================================== SAMPLE 1 ========================================\n",
            " {' 5'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "'Way in: take advanced: 5 go south: take south: take south: take: 5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Take shooter [ala: take squ: 5\n",
            "k take [make south: take crossover: take: 5\n",
            "There's face: 6 come down: 5\n",
            "\n",
            "\n",
            "For the plane: take get Just take going south, take south: just go south\n",
            "\n",
            "There is got going\n",
            "======================================== SAMPLE 2 ========================================\n",
            "} arrival =\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for each dish = level .4\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for level + level + level now\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "*\n",
            "\n",
            "\n",
            "for all\n",
            "\n",
            "for movement = level + level = total = level 2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for us =\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for level\n",
            "for this level = level\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for level +\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "for half\n",
            "======================================== SAMPLE 3 ========================================\n",
            "}1, screen: step: \\n, redbird :: return: they simply return us from {'------------------------ end = us\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Game = 3\n",
            "3\n",
            "So how = 3 {': we + appeal\n",
            "We = 5 = be\n",
            "Game = fail<|endoftext|>PH sin 2009\n",
            "So, Cultural Revolution of fan, under \"Well, 2 and National Revolution | go\n",
            "Our Revolution, here\n",
            "So will\n",
            "The Pink<|endoftext|>EN, Femin\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdwAXFicwMI1"
      },
      "source": [
        ""
      ]
    }
  ]
}